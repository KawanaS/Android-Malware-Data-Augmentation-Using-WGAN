# -*- coding: utf-8 -*-
"""
Created on Wed May 24 15:53:47 2023

@author: Kawana S
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import matplotlib.pyplot as plt
import numpy as np
import cv2
import os
from tensorflow.python.ops.numpy_ops import np_config
from numpy import cov
from numpy import trace
from numpy import iscomplexobj
from numpy import asarray
from numpy.random import randint
from scipy.linalg import sqrtm
from keras.applications.inception_v3 import InceptionV3
from keras.applications.inception_v3 import preprocess_input
from keras.datasets.mnist import load_data
from skimage.transform import resize
import openpyxl
import csv
import io
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Reshape, BatchNormalization, UpSampling2D, Conv2D
from tensorflow.keras.layers import Conv2D, Flatten, Dense

np_config.enable_numpy_behavior()

os.environ["CUDA_VISIBLE_DEVICES"]="1" #Num of GPUs
#mirrored_strategy = tf.distribute.MirroredStrategy(devices=["/gpu:0","/gpu:1"])
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

config = tf.compat.v1.ConfigProto(device_count={'GPU': 1})
config.gpu_options.allow_growth = True
sess = tf.compat.v1.Session(config=config)


DATA_DIR = 'E:/Python/Machine_Learning/Android_source_code_analysis/Drebin/'
CATEGORIES = ['malware_1']
#IMG_SHAPE = (28, 28, 1)
IMG_SIZE = 28
BATCH_SIZE = 5
noise_dim = 128

training_data = []

def create_training_data():
    for category in CATEGORIES:
        # path to goodware and malware images used for training
        path = os.path.join(DATA_DIR, category)
        class_num = CATEGORIES.index(category)
        for img in os.listdir(path):
            img_array = cv2.imread(os.path.join(path, img),cv2.IMREAD_GRAYSCALE)
            new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))
            training_data.append([new_array, class_num])

create_training_data()

MNIST_DATA = keras.datasets.mnist

#(train_images, train_labels), (test_images, test_labels) = MNIST_DATA.load_data()
#(train_images, train_labels), (test_images, test_labels) = training_data
train_images = []
train_labels = []

for features, label in training_data:
    train_images.append(features)
    train_labels.append(label)

'''selected_ix = y == 1
X = X[selected_ix]'''

train_images = np.array(train_images)


#train_images = train_images.reshape(train_images.shape[0], *IMG_SHAPE).astype("float32")
train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')
train_images = (train_images - 127.5) / 127.5


latent_dim = 100  # Adjust based on your needs

generator = Sequential()

# Dense layer to map from latent space to initial convolutional layer
generator.add(Dense(128 * 128 * 64, input_dim=latent_dim))
generator.add(Reshape((128, 128, 64)))

# Upsampling and Convolutional layers
generator.add(UpSampling2D())
generator.add(Conv2D(128, kernel_size=3, padding='same', activation='relu'))
generator.add(BatchNormalization())

generator.add(UpSampling2D())
generator.add(Conv2D(64, kernel_size=3, padding='same', activation='relu'))
generator.add(BatchNormalization())
# Output layer
generator.add(Conv2D(1, kernel_size=3, padding='same', activation='sigmoid'))


critic = Sequential()
# Convolutional layers
critic.add(Conv2D(64, kernel_size=3, padding='same', input_shape=(128, 128, 1)))
critic.add(Conv2D(64, kernel_size=3, strides=2, padding='same', activation='relu'))
critic.add(Conv2D(128, kernel_size=3, strides=2, padding='same', activation='relu'))
critic.add(Flatten())

# Dense layers
critic.add(Dense(1))

# Start training the model.
#with tf.device("gpu:0"):
#wgan.fit(train_images, batch_size=BATCH_SIZE, epochs=epochs, callbacks=[cbk])

'''epochs = range(1, 1001)

gen_loss = history.history['g_loss']
disc_loss = history.history['d_loss']

plt.plot(epochs,gen_loss, label='Generator Loss')
plt.plot(epochs,disc_loss, label='Discriminator Loss')
plt.title('Training Loss')
plt.xlabel('Epochs')
plt.ylabel('Training Loss')
plt.legend()
plt.show()'''

print(generator.summary())
print(critic.summary())
#wgan.save('goodware_GEN+DISC_28x28.h5')